{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No module named 'fairlearn': ExponentiatedGradientReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'inFairness': SenSeI and SenSR will be unavailable. To install, run:\n",
      "pip install 'aif360[inFairness]'\n",
      "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
      "pip install 'aif360[Reductions]'\n",
      "WARNING:root:No module named 'ot': ot_distance will be unavailable. To install, run:\n",
      "pip install 'aif360[OptimalTransport]'\n",
      "WARNING:root:No module named 'rpy2': FairAdapt will be unavailable. To install, run:\n",
      "pip install 'aif360[FairAdapt]'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from aif360.sklearn.datasets import standardize_dataset\n",
    "from aif360.sklearn.metrics import statistical_parity_difference, disparate_impact_ratio,\\\n",
    "                                   equal_opportunity_difference, average_odds_difference, \\\n",
    "                                   generalized_entropy_index, theil_index\n",
    "from aif360.sklearn.preprocessing import Reweighing\n",
    "from aif360.sklearn.postprocessing import CalibratedEqualizedOdds, PostProcessingMeta, RejectOptionClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loandata = pd.read_csv('../LoanData_prepared.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(241909, 21)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(loandata)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 241909 entries, 0 to 241908\n",
      "Data columns (total 21 columns):\n",
      " #   Column                             Non-Null Count   Dtype  \n",
      "---  ------                             --------------   -----  \n",
      " 0   AppliedAmount                      241909 non-null  float64\n",
      " 1   DebtToIncome                       241909 non-null  float64\n",
      " 2   AmountOfPreviousLoansBeforeLoan    241909 non-null  float64\n",
      " 3   Country                            241909 non-null  object \n",
      " 4   Education                          241909 non-null  object \n",
      " 5   EmploymentDurationCurrentEmployer  241909 non-null  object \n",
      " 6   ExistingLiabilities                241909 non-null  int64  \n",
      " 7   FreeCash                           241909 non-null  float64\n",
      " 8   Gender                             241909 non-null  object \n",
      " 9   HomeOwnershipType                  241909 non-null  object \n",
      " 10  IncomeTotal                        241909 non-null  float64\n",
      " 11  Interest                           241909 non-null  float64\n",
      " 12  LiabilitiesTotal                   241909 non-null  float64\n",
      " 13  LoanDuration                       241909 non-null  int64  \n",
      " 14  MonthlyPayment                     241909 non-null  float64\n",
      " 15  NewCreditCustomer                  241909 non-null  int64  \n",
      " 16  NoOfPreviousLoansBeforeLoan        241909 non-null  float64\n",
      " 17  VerificationType                   241909 non-null  object \n",
      " 18  LanguageCode                       241909 non-null  object \n",
      " 19  Default                            241909 non-null  int64  \n",
      " 20  Age_Group                          241909 non-null  object \n",
      "dtypes: float64(9), int64(4), object(8)\n",
      "memory usage: 38.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AppliedAmount                        0\n",
       "DebtToIncome                         0\n",
       "AmountOfPreviousLoansBeforeLoan      0\n",
       "Country                              0\n",
       "Education                            0\n",
       "EmploymentDurationCurrentEmployer    0\n",
       "ExistingLiabilities                  0\n",
       "FreeCash                             0\n",
       "Gender                               0\n",
       "HomeOwnershipType                    0\n",
       "IncomeTotal                          0\n",
       "Interest                             0\n",
       "LiabilitiesTotal                     0\n",
       "LoanDuration                         0\n",
       "MonthlyPayment                       0\n",
       "NewCreditCustomer                    0\n",
       "NoOfPreviousLoansBeforeLoan          0\n",
       "VerificationType                     0\n",
       "LanguageCode                         0\n",
       "Default                              0\n",
       "Age_Group                            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "protected = ['LanguageCode_Estonian']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "priv_group_dict = {'LanguageCode_Estonian':1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fair Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df)\n",
    "\n",
    "\n",
    "\n",
    "X, y = standardize_dataset(df, prot_attr=protected, target='Default')\n",
    "\n",
    "#Initialize Reweighing\n",
    "RW = Reweighing(prot_attr=protected)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42, stratify=y)\n",
    "\n",
    "# Do the reweighing on the data\n",
    "# Sample weights are saved in new variable sample_weights!\n",
    "X_train, sample_weights = RW.fit_transform(X_train, y_train)\n",
    "\n",
    "scaler=StandardScaler().set_output(transform='pandas')\n",
    "\n",
    "# Select numerical features from training data\n",
    "numerical_features = X_train.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "# Fit scaler to training data\n",
    "scaler.fit(X_train[numerical_features])\n",
    "\n",
    "# Transform training and testing data using scaler\n",
    "X_train = scaler.transform(X_train[numerical_features])\n",
    "X_test = scaler.transform(X_test[numerical_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Education_Basic education\n",
       "False    236457\n",
       "True       5452\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['Education_Basic education'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reweighing pre- & in-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribute LanguageCode_Estonian\n",
      "Statistical Parity Difference (SPD):\t\t\t0.0000\n",
      "Disparate Impact (DI):\t\t\t\t\t1.0000\n"
     ]
    }
   ],
   "source": [
    "for p in protected:\n",
    "      print('Attribute', p)\n",
    "      print('Statistical Parity Difference (SPD):\\t\\t\\t%.4f' %\\\n",
    "            statistical_parity_difference(y_train, prot_attr=p,  priv_group=priv_group_dict[p], sample_weight=sample_weights))\n",
    "      print('Disparate Impact (DI):\\t\\t\\t\\t\\t%.4f' %\\\n",
    "            disparate_impact_ratio(y_train, prot_attr=p, priv_group=priv_group_dict[p], sample_weight=sample_weights))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building estimator 1 of 50 for this parallel run (total 50)...\n",
      "Building estimator 2 of 50 for this parallel run (total 50)...\n",
      "Building estimator 3 of 50 for this parallel run (total 50)...\n",
      "Building estimator 4 of 50 for this parallel run (total 50)...\n",
      "Building estimator 5 of 50 for this parallel run (total 50)...\n",
      "Building estimator 6 of 50 for this parallel run (total 50)...\n",
      "Building estimator 7 of 50 for this parallel run (total 50)...\n",
      "Building estimator 8 of 50 for this parallel run (total 50)...\n",
      "Building estimator 9 of 50 for this parallel run (total 50)...\n",
      "Building estimator 10 of 50 for this parallel run (total 50)...\n",
      "Building estimator 11 of 50 for this parallel run (total 50)...\n",
      "Building estimator 12 of 50 for this parallel run (total 50)...\n",
      "Building estimator 13 of 50 for this parallel run (total 50)...\n",
      "Building estimator 14 of 50 for this parallel run (total 50)...\n",
      "Building estimator 15 of 50 for this parallel run (total 50)...\n",
      "Building estimator 16 of 50 for this parallel run (total 50)...\n",
      "Building estimator 17 of 50 for this parallel run (total 50)...\n",
      "Building estimator 18 of 50 for this parallel run (total 50)...\n",
      "Building estimator 19 of 50 for this parallel run (total 50)...\n",
      "Building estimator 20 of 50 for this parallel run (total 50)...\n",
      "Building estimator 21 of 50 for this parallel run (total 50)...\n",
      "Building estimator 22 of 50 for this parallel run (total 50)...\n",
      "Building estimator 23 of 50 for this parallel run (total 50)...\n",
      "Building estimator 24 of 50 for this parallel run (total 50)...\n",
      "Building estimator 25 of 50 for this parallel run (total 50)...\n",
      "Building estimator 26 of 50 for this parallel run (total 50)...\n",
      "Building estimator 27 of 50 for this parallel run (total 50)...\n",
      "Building estimator 28 of 50 for this parallel run (total 50)...\n",
      "Building estimator 29 of 50 for this parallel run (total 50)...\n",
      "Building estimator 30 of 50 for this parallel run (total 50)...\n",
      "Building estimator 31 of 50 for this parallel run (total 50)...\n",
      "Building estimator 32 of 50 for this parallel run (total 50)...\n",
      "Building estimator 33 of 50 for this parallel run (total 50)...\n",
      "Building estimator 34 of 50 for this parallel run (total 50)...\n",
      "Building estimator 35 of 50 for this parallel run (total 50)...\n",
      "Building estimator 36 of 50 for this parallel run (total 50)...\n",
      "Building estimator 37 of 50 for this parallel run (total 50)...\n",
      "Building estimator 38 of 50 for this parallel run (total 50)...\n",
      "Building estimator 39 of 50 for this parallel run (total 50)...\n",
      "Building estimator 40 of 50 for this parallel run (total 50)...\n",
      "Building estimator 41 of 50 for this parallel run (total 50)...\n",
      "Building estimator 42 of 50 for this parallel run (total 50)...\n",
      "Building estimator 43 of 50 for this parallel run (total 50)...\n",
      "Building estimator 44 of 50 for this parallel run (total 50)...\n",
      "Building estimator 45 of 50 for this parallel run (total 50)...\n",
      "Building estimator 46 of 50 for this parallel run (total 50)...\n",
      "Building estimator 47 of 50 for this parallel run (total 50)...\n",
      "Building estimator 48 of 50 for this parallel run (total 50)...\n",
      "Building estimator 49 of 50 for this parallel run (total 50)...\n",
      "Building estimator 50 of 50 for this parallel run (total 50)...\n",
      "Out:  0.656731842420735\n",
      "In:  0.9661993955483699\n"
     ]
    }
   ],
   "source": [
    "BAG = BaggingClassifier(n_estimators=50, estimator=RandomForestClassifier(n_estimators=25, max_depth=35,random_state=42), random_state=42, warm_start=True, verbose=2)\n",
    "\n",
    "BAG.fit(X_train, y_train, sample_weight=sample_weights)\n",
    "print(\"Out: \",accuracy_score(y_test, BAG.predict(X_test)))\n",
    "print(\"In: \",accuracy_score(y_train, BAG.predict(X_train)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = BAG.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.75      0.72     14033\n",
      "           1       0.60      0.53      0.57     10158\n",
      "\n",
      "    accuracy                           0.66     24191\n",
      "   macro avg       0.65      0.64      0.64     24191\n",
      "weighted avg       0.65      0.66      0.65     24191\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate a classification report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\\n\", class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 2 ... 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "y_test_np = y_test.to_numpy()\n",
    "\n",
    "b = np.array([y_pred[i] - y_test_np[i] + 1 for i in range(len(y_pred) - 1)])\n",
    "\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LanguageCode_Estonian\n"
     ]
    }
   ],
   "source": [
    "SPD = []\n",
    "DI = []\n",
    "EqualOpp = []\n",
    "AverageOdds = []\n",
    "GEI = []\n",
    "Theil = []\n",
    "\n",
    "for attr in protected:\n",
    "    print(attr)\n",
    "    spd_score = statistical_parity_difference(y_test, y_pred, prot_attr=attr, priv_group=priv_group_dict[attr])\n",
    "    SPD.append(spd_score)\n",
    "    di_score = disparate_impact_ratio(y_test, y_pred, prot_attr=attr, priv_group=priv_group_dict[attr])\n",
    "    DI.append(di_score)\n",
    "    equalopp = equal_opportunity_difference(y_test, y_pred, prot_attr=attr, priv_group=priv_group_dict[attr])\n",
    "    EqualOpp.append(equalopp)\n",
    "    averageodd = average_odds_difference(y_test, y_pred, prot_attr=attr, priv_group=priv_group_dict[attr])\n",
    "    AverageOdds.append(averageodd)\n",
    "    gei = generalized_entropy_index(b=b, alpha=2)\n",
    "    GEI.append(gei)\n",
    "    theil = generalized_entropy_index(b=b, alpha=1)\n",
    "    Theil.append(theil)\n",
    "\n",
    "\n",
    "df_bias = pd.DataFrame({'Protected_feature':protected,'Statistical_Parity':SPD,'Disparate_Impact':DI, 'Equal Opportunity difference':EqualOpp, 'Equalized Odds difference': AverageOdds, 'GEI':GEI, 'Theil':Theil})\n",
    "df_bias['DI_normal']=df_bias[\"Disparate_Impact\"].apply(lambda x: 1/x if x < 1 else x)\n",
    "df_bias['SPD_normal']=df_bias[\"Statistical_Parity\"].apply(lambda x: abs(x) if x < 0 else x)\n",
    "df_bias['EoppD_normal']=df_bias[\"Equal Opportunity difference\"].apply(lambda x: abs(x) if x < 0 else x)\n",
    "df_bias['EoddsD_normal']=df_bias[\"Equalized Odds difference\"].apply(lambda x: abs(x) if x < 0 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Protected_feature</th>\n",
       "      <th>DI_normal</th>\n",
       "      <th>SPD_normal</th>\n",
       "      <th>EoppD_normal</th>\n",
       "      <th>EoddsD_normal</th>\n",
       "      <th>GEI</th>\n",
       "      <th>Theil</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LanguageCode_Estonian</td>\n",
       "      <td>1.901094</td>\n",
       "      <td>0.214118</td>\n",
       "      <td>0.181256</td>\n",
       "      <td>0.173072</td>\n",
       "      <td>0.188382</td>\n",
       "      <td>0.264612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Protected_feature  DI_normal  SPD_normal  EoppD_normal  EoddsD_normal  \\\n",
       "0  LanguageCode_Estonian   1.901094    0.214118      0.181256       0.173072   \n",
       "\n",
       "        GEI     Theil  \n",
       "0  0.188382  0.264612  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bias.loc[:,['Protected_feature', 'DI_normal', 'SPD_normal', 'EoppD_normal', 'EoddsD_normal', 'GEI', 'Theil']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building estimator 1 of 50 for this parallel run (total 50)...\n",
      "Building estimator 2 of 50 for this parallel run (total 50)...\n",
      "Building estimator 3 of 50 for this parallel run (total 50)...\n",
      "Building estimator 4 of 50 for this parallel run (total 50)...\n",
      "Building estimator 5 of 50 for this parallel run (total 50)...\n",
      "Building estimator 6 of 50 for this parallel run (total 50)...\n",
      "Building estimator 7 of 50 for this parallel run (total 50)...\n",
      "Building estimator 8 of 50 for this parallel run (total 50)...\n",
      "Building estimator 9 of 50 for this parallel run (total 50)...\n",
      "Building estimator 10 of 50 for this parallel run (total 50)...\n",
      "Building estimator 11 of 50 for this parallel run (total 50)...\n",
      "Building estimator 12 of 50 for this parallel run (total 50)...\n",
      "Building estimator 13 of 50 for this parallel run (total 50)...\n",
      "Building estimator 14 of 50 for this parallel run (total 50)...\n",
      "Building estimator 15 of 50 for this parallel run (total 50)...\n",
      "Building estimator 16 of 50 for this parallel run (total 50)...\n",
      "Building estimator 17 of 50 for this parallel run (total 50)...\n",
      "Building estimator 18 of 50 for this parallel run (total 50)...\n",
      "Building estimator 19 of 50 for this parallel run (total 50)...\n",
      "Building estimator 20 of 50 for this parallel run (total 50)...\n",
      "Building estimator 21 of 50 for this parallel run (total 50)...\n",
      "Building estimator 22 of 50 for this parallel run (total 50)...\n",
      "Building estimator 23 of 50 for this parallel run (total 50)...\n",
      "Building estimator 24 of 50 for this parallel run (total 50)...\n",
      "Building estimator 25 of 50 for this parallel run (total 50)...\n",
      "Building estimator 26 of 50 for this parallel run (total 50)...\n",
      "Building estimator 27 of 50 for this parallel run (total 50)...\n",
      "Building estimator 28 of 50 for this parallel run (total 50)...\n",
      "Building estimator 29 of 50 for this parallel run (total 50)...\n",
      "Building estimator 30 of 50 for this parallel run (total 50)...\n",
      "Building estimator 31 of 50 for this parallel run (total 50)...\n",
      "Building estimator 32 of 50 for this parallel run (total 50)...\n",
      "Building estimator 33 of 50 for this parallel run (total 50)...\n",
      "Building estimator 34 of 50 for this parallel run (total 50)...\n",
      "Building estimator 35 of 50 for this parallel run (total 50)...\n",
      "Building estimator 36 of 50 for this parallel run (total 50)...\n",
      "Building estimator 37 of 50 for this parallel run (total 50)...\n",
      "Building estimator 38 of 50 for this parallel run (total 50)...\n",
      "Building estimator 39 of 50 for this parallel run (total 50)...\n",
      "Building estimator 40 of 50 for this parallel run (total 50)...\n",
      "Building estimator 41 of 50 for this parallel run (total 50)...\n",
      "Building estimator 42 of 50 for this parallel run (total 50)...\n",
      "Building estimator 43 of 50 for this parallel run (total 50)...\n",
      "Building estimator 44 of 50 for this parallel run (total 50)...\n",
      "Building estimator 45 of 50 for this parallel run (total 50)...\n",
      "Building estimator 46 of 50 for this parallel run (total 50)...\n",
      "Building estimator 47 of 50 for this parallel run (total 50)...\n",
      "Building estimator 48 of 50 for this parallel run (total 50)...\n",
      "Building estimator 49 of 50 for this parallel run (total 50)...\n",
      "Building estimator 50 of 50 for this parallel run (total 50)...\n",
      "Out:  0.4904716630151709\n",
      "In:  0.5588789167638872\n"
     ]
    }
   ],
   "source": [
    "ROC = RejectOptionClassifier(prot_attr=protected, threshold=0.1, margin=0.1)\n",
    "\n",
    "postproc = PostProcessingMeta(estimator=BaggingClassifier(n_estimators=50, estimator=RandomForestClassifier(n_estimators=25, max_depth=35,random_state=42), random_state=42, warm_start=True, verbose=2), \n",
    "                              postprocessor=ROC, random_state=42, val_size=0.1)\n",
    "\n",
    "postproc.fit(X_train, y_train)\n",
    "print(\"Out: \",accuracy_score(y_test, postproc.predict(X_test)))\n",
    "print(\"In: \",accuracy_score(y_train, postproc.predict(X_train)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = postproc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.14      0.24     14033\n",
      "           1       0.45      0.98      0.62     10158\n",
      "\n",
      "    accuracy                           0.49     24191\n",
      "   macro avg       0.68      0.56      0.43     24191\n",
      "weighted avg       0.71      0.49      0.40     24191\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate a classification report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\\n\", class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 ... 1 1 2]\n"
     ]
    }
   ],
   "source": [
    "y_test_np = y_test.to_numpy()\n",
    "\n",
    "b = np.array([y_pred[i] - y_test_np[i] + 1 for i in range(len(y_pred) - 1)])\n",
    "\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LanguageCode_Estonian\n"
     ]
    }
   ],
   "source": [
    "SPD = []\n",
    "DI = []\n",
    "EqualOpp = []\n",
    "AverageOdds = []\n",
    "GEI = []\n",
    "Theil = []\n",
    "\n",
    "for attr in protected:\n",
    "    print(attr)\n",
    "    spd_score = statistical_parity_difference(y_test, y_pred, prot_attr=attr, priv_group=priv_group_dict[attr])\n",
    "    SPD.append(spd_score)\n",
    "    di_score = disparate_impact_ratio(y_test, y_pred, prot_attr=attr, priv_group=priv_group_dict[attr])\n",
    "    DI.append(di_score)\n",
    "    equalopp = equal_opportunity_difference(y_test, y_pred, prot_attr=attr, priv_group=priv_group_dict[attr])\n",
    "    EqualOpp.append(equalopp)\n",
    "    averageodd = average_odds_difference(y_test, y_pred, prot_attr=attr, priv_group=priv_group_dict[attr])\n",
    "    AverageOdds.append(averageodd)\n",
    "    gei = generalized_entropy_index(b=b, alpha=2)\n",
    "    GEI.append(gei)\n",
    "    theil = generalized_entropy_index(b=b, alpha=1)\n",
    "    Theil.append(theil)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bias = pd.DataFrame({'Protected_feature':protected,'Statistical_Parity':SPD,'Disparate_Impact':DI, 'Equal Opportunity difference':EqualOpp, 'Equalized Odds difference': AverageOdds, 'GEI':GEI, 'Theil':Theil})\n",
    "df_bias['DI_normal']=df_bias[\"Disparate_Impact\"].apply(lambda x: 1/x if x < 1 else x)\n",
    "df_bias['SPD_normal']=df_bias[\"Statistical_Parity\"].apply(lambda x: abs(x) if x < 0 else x)\n",
    "df_bias['EoppD_normal']=df_bias[\"Equal Opportunity difference\"].apply(lambda x: abs(x) if x < 0 else x)\n",
    "df_bias['EoddsD_normal']=df_bias[\"Equalized Odds difference\"].apply(lambda x: abs(x) if x < 0 else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Protected_feature</th>\n",
       "      <th>DI_normal</th>\n",
       "      <th>SPD_normal</th>\n",
       "      <th>EoppD_normal</th>\n",
       "      <th>EoddsD_normal</th>\n",
       "      <th>GEI</th>\n",
       "      <th>Theil</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LanguageCode_Estonian</td>\n",
       "      <td>1.304181</td>\n",
       "      <td>0.233204</td>\n",
       "      <td>0.073736</td>\n",
       "      <td>0.189719</td>\n",
       "      <td>0.060027</td>\n",
       "      <td>0.065084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Protected_feature  DI_normal  SPD_normal  EoppD_normal  EoddsD_normal  \\\n",
       "0  LanguageCode_Estonian   1.304181    0.233204      0.073736       0.189719   \n",
       "\n",
       "        GEI     Theil  \n",
       "0  0.060027  0.065084  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bias.loc[:,['Protected_feature', 'DI_normal', 'SPD_normal', 'EoppD_normal', 'EoddsD_normal', 'GEI', 'Theil']].head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "benv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
